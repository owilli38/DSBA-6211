{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPgdeZODU275wJwJa6QYMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owilli38/DSBA-6211/blob/main/DSBA6162_Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c55iW5VTbphs",
        "outputId": "1c96807d-ca79-4835-ad56-ab07eec5c13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/My Drive/ColabData\n",
        "%cd /content/drive/My Drive/ColabData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQQ23E7jcms4",
        "outputId": "09b87619-7f3b-4aaa-f35f-3422417b0ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ColabData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "\n",
        "# Load the corpus\n",
        "corpus_root = 'MovieReviews.zip'\n",
        "filelists = PlaintextCorpusReader(corpus_root, '.*', encoding='latin-1')\n",
        "\n",
        "# Build docs = [(author, words), ...]\n",
        "docs = []\n",
        "fileids = filelists.fileids()\n",
        "\n",
        "# import the shorttext library for text preprocessing\n",
        "from shorttext.utils import standard_text_preprocessor_1\n",
        "preprocessor = standard_text_preprocessor_1()\n",
        "\n",
        "\n",
        "for i, fid in enumerate(fileids):\n",
        "    # Use preprocessed and stemmed words, and convert to a set\n",
        "    words_processed = set(preprocessor(filelists.raw(fid)).split(' '))\n",
        "    if i < 80:\n",
        "        author = \"B\"  # Berardinelli\n",
        "    else:\n",
        "        author = \"S\"  # Schwartz\n",
        "    docs.append((author, words_processed))"
      ],
      "metadata": {
        "id": "0LfkE1j4cppd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[25]"
      ],
      "metadata": {
        "id": "6Cpsdq5ndRjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e556e49-1f72-4017-bc0e-17ee946eac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('B',\n",
              " {'',\n",
              "  '\\ndenni',\n",
              "  '\\ntruli',\n",
              "  'absorb',\n",
              "  'accus',\n",
              "  'address',\n",
              "  'adjust',\n",
              "  'afterward',\n",
              "  'almost',\n",
              "  'america',\n",
              "  'america\\nbi',\n",
              "  'american',\n",
              "  'apocalypt',\n",
              "  'appropri',\n",
              "  'argu',\n",
              "  'around',\n",
              "  'ask',\n",
              "  'atmospher',\n",
              "  'aton',\n",
              "  'attack',\n",
              "  'attempt',\n",
              "  'audienc',\n",
              "  'beauti',\n",
              "  'becam',\n",
              "  'becom',\n",
              "  'bed',\n",
              "  'behold',\n",
              "  'beth',\n",
              "  'bill',\n",
              "  'blair',\n",
              "  'brad',\n",
              "  'bring',\n",
              "  'build',\n",
              "  'builtup',\n",
              "  'busi',\n",
              "  'businessmen',\n",
              "  'camera',\n",
              "  'captur',\n",
              "  'care',\n",
              "  'cast',\n",
              "  'certain',\n",
              "  'charact',\n",
              "  'clarifi',\n",
              "  'classic',\n",
              "  'clearer',\n",
              "  'closer',\n",
              "  'collegeag',\n",
              "  'come',\n",
              "  'comfort',\n",
              "  'commerci',\n",
              "  'communic',\n",
              "  'compar',\n",
              "  'complet',\n",
              "  'complic',\n",
              "  'confront',\n",
              "  'consum',\n",
              "  'convers',\n",
              "  'could',\n",
              "  'countri',\n",
              "  'cowork',\n",
              "  'critic',\n",
              "  'cultur',\n",
              "  'daili',\n",
              "  'daughter',\n",
              "  'day',\n",
              "  'deal',\n",
              "  'deem',\n",
              "  'deepest',\n",
              "  'definit',\n",
              "  'deliber',\n",
              "  'denni',\n",
              "  'depart',\n",
              "  'despis',\n",
              "  'destroy',\n",
              "  'didnt',\n",
              "  'difficult',\n",
              "  'difficulti',\n",
              "  'dine',\n",
              "  'diner',\n",
              "  'director',\n",
              "  'dispass',\n",
              "  'disturb',\n",
              "  'doesnt',\n",
              "  'dollar',\n",
              "  'doug',\n",
              "  'easi',\n",
              "  'econom',\n",
              "  'ellen',\n",
              "  'emerson',\n",
              "  'emul',\n",
              "  'essay',\n",
              "  'europ',\n",
              "  'evas',\n",
              "  'even',\n",
              "  'exact',\n",
              "  'exhibit',\n",
              "  'exil',\n",
              "  'experi',\n",
              "  'explor',\n",
              "  'expos',\n",
              "  'extraordinari',\n",
              "  'face',\n",
              "  'famili',\n",
              "  'fear',\n",
              "  'feel',\n",
              "  'film',\n",
              "  'filmmak',\n",
              "  'find',\n",
              "  'first',\n",
              "  'flash',\n",
              "  'flyfish',\n",
              "  'focus',\n",
              "  'forc',\n",
              "  'foreign',\n",
              "  'found',\n",
              "  'fulli',\n",
              "  'fumbl',\n",
              "  'gaddi',\n",
              "  'gentil',\n",
              "  'get',\n",
              "  'gibraltor',\n",
              "  'give',\n",
              "  'go',\n",
              "  'go\\njost',\n",
              "  'god',\n",
              "  'good',\n",
              "  'grip',\n",
              "  'hand',\n",
              "  'happi',\n",
              "  'hard',\n",
              "  'haunt',\n",
              "  'hear',\n",
              "  'held',\n",
              "  'home',\n",
              "  'import',\n",
              "  'impos',\n",
              "  'independ',\n",
              "  'individu',\n",
              "  'inher',\n",
              "  'insati',\n",
              "  'insist',\n",
              "  'interact',\n",
              "  'japanes',\n",
              "  'jon',\n",
              "  'jost',\n",
              "  'justifi',\n",
              "  'kate',\n",
              "  'kind',\n",
              "  'know',\n",
              "  'landscap',\n",
              "  'laps',\n",
              "  'letter',\n",
              "  'life',\n",
              "  'line',\n",
              "  'live',\n",
              "  'long',\n",
              "  'look',\n",
              "  'lose',\n",
              "  'lot',\n",
              "  'loud',\n",
              "  'love',\n",
              "  'lumber',\n",
              "  'made',\n",
              "  'make',\n",
              "  'malais',\n",
              "  'manner',\n",
              "  'marriag',\n",
              "  'marshal',\n",
              "  'matter',\n",
              "  'mclaughlin',\n",
              "  'mean',\n",
              "  'meet',\n",
              "  'memor',\n",
              "  'metaphor',\n",
              "  'meticul',\n",
              "  'microscop',\n",
              "  'mill',\n",
              "  'mix',\n",
              "  'money\\nour',\n",
              "  'move',\n",
              "  'movi',\n",
              "  'mrs',\n",
              "  'muffl',\n",
              "  'mysteri',\n",
              "  'natur',\n",
              "  'nature\\non',\n",
              "  'necess',\n",
              "  'need',\n",
              "  'never',\n",
              "  'news',\n",
              "  'nonact',\n",
              "  'nuanc',\n",
              "  'odd',\n",
              "  'offer',\n",
              "  'one',\n",
              "  'oregon',\n",
              "  'other',\n",
              "  'outcome\\nthi',\n",
              "  'owner',\n",
              "  'pan',\n",
              "  'part',\n",
              "  'patron',\n",
              "  'penetr',\n",
              "  'peopl',\n",
              "  'people\\nreview',\n",
              "  'perceiv',\n",
              "  'percept',\n",
              "  'perhap',\n",
              "  'period',\n",
              "  'persona',\n",
              "  'pick',\n",
              "  'pictur',\n",
              "  'place',\n",
              "  'play',\n",
              "  'pocket',\n",
              "  'poetri',\n",
              "  'point',\n",
              "  'power',\n",
              "  'prais',\n",
              "  'pray',\n",
              "  'preacher',\n",
              "  'precis',\n",
              "  'principl',\n",
              "  'privat',\n",
              "  'probabl',\n",
              "  'put',\n",
              "  'question',\n",
              "  'quick',\n",
              "  'rare',\n",
              "  'rather',\n",
              "  'rave',\n",
              "  'raw',\n",
              "  'ray',\n",
              "  'read',\n",
              "  'real',\n",
              "  'receiv',\n",
              "  'religi',\n",
              "  'remain',\n",
              "  'replet',\n",
              "  'reserv',\n",
              "  'respond',\n",
              "  'rest',\n",
              "  'result',\n",
              "  'return',\n",
              "  'reviews\\na',\n",
              "  'right',\n",
              "  'rock',\n",
              "  'rural',\n",
              "  'sannella',\n",
              "  'say',\n",
              "  'scene',\n",
              "  'schwartz',\n",
              "  'schwartz\\n',\n",
              "  'scott',\n",
              "  'screen',\n",
              "  'script',\n",
              "  'second',\n",
              "  'see',\n",
              "  'self',\n",
              "  'sens',\n",
              "  'settl',\n",
              "  'shelton',\n",
              "  'shocker',\n",
              "  'shot',\n",
              "  'shotthi',\n",
              "  'shout',\n",
              "  'sight',\n",
              "  'sinc',\n",
              "  'sleep',\n",
              "  'socal',\n",
              "  'soon',\n",
              "  'soul',\n",
              "  'sport',\n",
              "  'squelch',\n",
              "  'steadfast',\n",
              "  'stori',\n",
              "  'stranger',\n",
              "  'street',\n",
              "  'strong',\n",
              "  'subject',\n",
              "  'subt',\n",
              "  'sure',\n",
              "  'symbol',\n",
              "  'tell',\n",
              "  'territori',\n",
              "  'therefor',\n",
              "  'thing',\n",
              "  'think',\n",
              "  'thrust',\n",
              "  'time',\n",
              "  'told',\n",
              "  'tom',\n",
              "  'traci',\n",
              "  'tragic',\n",
              "  'tri',\n",
              "  'trilog',\n",
              "  'true',\n",
              "  'truth',\n",
              "  'type',\n",
              "  'unansw',\n",
              "  'uncomfort',\n",
              "  'unfold',\n",
              "  'unglu',\n",
              "  'unsettl',\n",
              "  'use',\n",
              "  'via',\n",
              "  'view',\n",
              "  'violent',\n",
              "  'wad',\n",
              "  'want',\n",
              "  'wealthi',\n",
              "  'weiss',\n",
              "  'whose',\n",
              "  'wife',\n",
              "  'willing',\n",
              "  'wonder',\n",
              "  'work',\n",
              "  'world',\n",
              "  'write',\n",
              "  'year',\n",
              "  'zealot'})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the shorttext library for text preprocessing\n",
        "#standard_text_preprocessor_1 under shorttext.utils provides a standard way of text preprocessing, including the following steps:\n",
        "\n",
        "   #1. removing special characters,\n",
        "   #2. removing numerals,\n",
        "   #3. converting all alphabets to lower cases,\n",
        "   #4. removing stop words, and\n",
        "   #5. stemming the words (using Porter stemmer).\n",
        "\n",
        "from shorttext.utils import standard_text_preprocessor_1, DocumentTermMatrix\n",
        "preprocessor = standard_text_preprocessor_1()\n",
        "# Join the set of words into a string before passing to the preprocessor\n",
        "corpus = [preprocessor(' '.join(article[1])).split(' ') for article in docs]"
      ],
      "metadata": {
        "id": "wB0zWZ_5dYM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[25]"
      ],
      "metadata": {
        "id": "x71jr17hdmY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d78df6-7438-4660-cefa-d296aced8a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'day',\n",
              " 'import',\n",
              " 'experi',\n",
              " 'flash',\n",
              " 'nature\\non',\n",
              " 'commerci',\n",
              " 'reserv',\n",
              " 'probabl',\n",
              " 'oregon',\n",
              " 'impo',\n",
              " 'insati',\n",
              " 'flyfish',\n",
              " 'lap',\n",
              " 'fulli',\n",
              " 'find',\n",
              " 'aton',\n",
              " 'shot',\n",
              " 'put',\n",
              " 'complic',\n",
              " 'bill',\n",
              " 'exact',\n",
              " 'expo',\n",
              " 'collegeag',\n",
              " 'think',\n",
              " 'strong',\n",
              " 'america\\nbi',\n",
              " 'shocker',\n",
              " 'wad',\n",
              " 'reviews\\na',\n",
              " 'mclaughlin',\n",
              " 'part',\n",
              " 'audienc',\n",
              " 'violent',\n",
              " 'prai',\n",
              " 'necess',\n",
              " 'jon',\n",
              " 'interact',\n",
              " 'around',\n",
              " 'mix',\n",
              " 'cowork',\n",
              " 'fumbl',\n",
              " 'stranger',\n",
              " 'traci',\n",
              " 'certain',\n",
              " 'wife',\n",
              " 'gibraltor',\n",
              " 'beauti',\n",
              " 'deepest',\n",
              " 'live',\n",
              " 'tri',\n",
              " 'religi',\n",
              " 'never',\n",
              " 'difficult',\n",
              " 'individu',\n",
              " 'subt',\n",
              " 'behold',\n",
              " 'inher',\n",
              " 'go\\njost',\n",
              " 'sinc',\n",
              " 'preacher',\n",
              " 'memor',\n",
              " 'exil',\n",
              " 'rock',\n",
              " 'famili',\n",
              " 'delib',\n",
              " 'kind',\n",
              " 'grip',\n",
              " 'daughter',\n",
              " 'odd',\n",
              " 'place',\n",
              " 'deal',\n",
              " 'lumber',\n",
              " 'businessmen',\n",
              " 'letter',\n",
              " 'atmosph',\n",
              " 'builtup',\n",
              " 'second',\n",
              " 'rather',\n",
              " 'period',\n",
              " 'cultur',\n",
              " 'schwartz\\n',\n",
              " 'becom',\n",
              " 'sannella',\n",
              " 'film',\n",
              " 'unsettl',\n",
              " 'patron',\n",
              " 'therefor',\n",
              " 'scott',\n",
              " 'american',\n",
              " 'thrust',\n",
              " 'persona',\n",
              " 'daili',\n",
              " 'self',\n",
              " 'screen',\n",
              " 'view',\n",
              " 'sight',\n",
              " 'consum',\n",
              " 'depart',\n",
              " 'definit',\n",
              " 'ask',\n",
              " 'disturb',\n",
              " 'unfold',\n",
              " 'deem',\n",
              " 'captur',\n",
              " 'conver',\n",
              " 'schwartz',\n",
              " 'explor',\n",
              " 'whose',\n",
              " 'tom',\n",
              " 'marshal',\n",
              " 'europ',\n",
              " 'clarifi',\n",
              " 'justifi',\n",
              " 'year',\n",
              " 'first',\n",
              " 'meticul',\n",
              " 'denni',\n",
              " 'go',\n",
              " 'beth',\n",
              " 'feel',\n",
              " 'destroy',\n",
              " 'work',\n",
              " 'wealthi',\n",
              " 'rave',\n",
              " 'true',\n",
              " 'receiv',\n",
              " 'gaddi',\n",
              " 'steadfast',\n",
              " 'know',\n",
              " 'exhibit',\n",
              " 'home',\n",
              " 'econom',\n",
              " 'rural',\n",
              " 'weiss',\n",
              " 'nuanc',\n",
              " 'symbol',\n",
              " 'respond',\n",
              " 'despi',\n",
              " 'kate',\n",
              " 'pick',\n",
              " 'fear',\n",
              " 'one',\n",
              " 'stori',\n",
              " 'clearer',\n",
              " 'pocket',\n",
              " 'street',\n",
              " 'tragic',\n",
              " 'independ',\n",
              " 'emul',\n",
              " 'jost',\n",
              " 'focus',\n",
              " 'return',\n",
              " 'hand',\n",
              " 'mrs',\n",
              " 'pan',\n",
              " 'move',\n",
              " 'right',\n",
              " 'lose',\n",
              " 'build',\n",
              " 'soul',\n",
              " 'script',\n",
              " 'matter',\n",
              " 'held',\n",
              " 'love',\n",
              " 'line',\n",
              " 'movi',\n",
              " 'sure',\n",
              " 'sport',\n",
              " 'foreign',\n",
              " 'perhap',\n",
              " 'shotthi',\n",
              " 'forc',\n",
              " 'scene',\n",
              " 'appropri',\n",
              " 'money\\nour',\n",
              " 'socal',\n",
              " 'diner',\n",
              " 'apocalypt',\n",
              " 'america',\n",
              " 'trilog',\n",
              " 'doug',\n",
              " 'almost',\n",
              " 'afterward',\n",
              " 'look',\n",
              " 'address',\n",
              " 'perceiv',\n",
              " 'write',\n",
              " 'need',\n",
              " 'manner',\n",
              " 'real',\n",
              " 'marriag',\n",
              " 'dispass',\n",
              " 'privat',\n",
              " 'mill',\n",
              " 'remain',\n",
              " 'could',\n",
              " 'principl',\n",
              " 'lot',\n",
              " 'classic',\n",
              " 'peopl',\n",
              " 'confront',\n",
              " 'good',\n",
              " 'outcome\\nthi',\n",
              " 'percept',\n",
              " 'malai',\n",
              " 'bed',\n",
              " 'microscop',\n",
              " 'question',\n",
              " 'give',\n",
              " 'rare',\n",
              " 'natur',\n",
              " 'squelch',\n",
              " 'truth',\n",
              " 'busi',\n",
              " 'pray',\n",
              " 'life',\n",
              " 'quick',\n",
              " 'mean',\n",
              " 'adjust',\n",
              " 'comfort',\n",
              " 'wonder',\n",
              " 'dine',\n",
              " 'result',\n",
              " 'director',\n",
              " 'camera',\n",
              " 'thing',\n",
              " 'filmmak',\n",
              " 'landscap',\n",
              " 'people\\nreview',\n",
              " 'brad',\n",
              " 'pictur',\n",
              " 'critic',\n",
              " 'absorb',\n",
              " '\\ndenni',\n",
              " 'care',\n",
              " 'soon',\n",
              " 'becam',\n",
              " 'complet',\n",
              " 'extraordinari',\n",
              " 'use',\n",
              " 'emerson',\n",
              " 'essay',\n",
              " 'happi',\n",
              " 'hear',\n",
              " 'attempt',\n",
              " 'didnt',\n",
              " 'japan',\n",
              " 'point',\n",
              " 'compar',\n",
              " 'attack',\n",
              " 'offer',\n",
              " 'get',\n",
              " 'raw',\n",
              " 'penetr',\n",
              " 'found',\n",
              " 'preci',\n",
              " 'ray',\n",
              " 'shelton',\n",
              " 'via',\n",
              " 'charact',\n",
              " 'loud',\n",
              " 'muffl',\n",
              " 'difficulti',\n",
              " 'dollar',\n",
              " 'poetri',\n",
              " 'unansw',\n",
              " 'power',\n",
              " 'insist',\n",
              " 'told',\n",
              " 'metaphor',\n",
              " 'replet',\n",
              " 'mysteri',\n",
              " 'zealot',\n",
              " 'read',\n",
              " 'unglu',\n",
              " 'easi',\n",
              " 'see',\n",
              " 'shout',\n",
              " 'haunt',\n",
              " 'will',\n",
              " '\\ntruli',\n",
              " 'sleep',\n",
              " 'tell',\n",
              " 'made',\n",
              " 'say',\n",
              " 'god',\n",
              " 'rest',\n",
              " 'owner',\n",
              " 'closer',\n",
              " 'make',\n",
              " 'cast',\n",
              " 'accus',\n",
              " 'even',\n",
              " 'hard',\n",
              " 'settl',\n",
              " 'type',\n",
              " 'nonact',\n",
              " 'countri',\n",
              " 'communic',\n",
              " 'time',\n",
              " 'meet',\n",
              " 'territori',\n",
              " 'news',\n",
              " 'world',\n",
              " 'argu',\n",
              " 'doesnt',\n",
              " 'play',\n",
              " 'long',\n",
              " 'subject',\n",
              " 'face',\n",
              " 'gentil',\n",
              " 'uncomfort',\n",
              " 'blair',\n",
              " 'eva',\n",
              " 'sen',\n",
              " 'bring']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtm = DocumentTermMatrix(corpus, docids = filelists.fileids())"
      ],
      "metadata": {
        "id": "PUkDktkCdrgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check number of occurence of the word \"director\" in each document\n",
        "dtm.get_token_occurences('director')"
      ],
      "metadata": {
        "id": "0K5mVnT8duyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4c68bf-469b-484c-a88b-d4d62dd92e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MovieReviews/16748.txt': 1.0,\n",
              " 'MovieReviews/17108.txt': 1.0,\n",
              " 'MovieReviews/17109.txt': 1.0,\n",
              " 'MovieReviews/17110.txt': 1.0,\n",
              " 'MovieReviews/17111.txt': 1.0,\n",
              " 'MovieReviews/17116.txt': 1.0,\n",
              " 'MovieReviews/17117.txt': 1.0,\n",
              " 'MovieReviews/17118.txt': 1.0,\n",
              " 'MovieReviews/17119.txt': 1.0,\n",
              " 'MovieReviews/17139.txt': 1.0,\n",
              " 'MovieReviews/17144.txt': 1.0,\n",
              " 'MovieReviews/17145.txt': 1.0,\n",
              " 'MovieReviews/17146.txt': 1.0,\n",
              " 'MovieReviews/17147.txt': 1.0,\n",
              " 'MovieReviews/17150.txt': 1.0,\n",
              " 'MovieReviews/17185.txt': 1.0,\n",
              " 'MovieReviews/17192.txt': 1.0,\n",
              " 'MovieReviews/17219.txt': 1.0,\n",
              " 'MovieReviews/17239.txt': 1.0,\n",
              " 'MovieReviews/17243.txt': 1.0,\n",
              " 'MovieReviews/17254.txt': 1.0,\n",
              " 'MovieReviews/17255.txt': 1.0,\n",
              " 'MovieReviews/17280.txt': 1.0,\n",
              " 'MovieReviews/17300.txt': 1.0,\n",
              " 'MovieReviews/17303.txt': 1.0,\n",
              " 'MovieReviews/17341.txt': 1.0,\n",
              " 'MovieReviews/17384.txt': 1.0,\n",
              " 'MovieReviews/17398.txt': 1.0,\n",
              " 'MovieReviews/17399.txt': 1.0,\n",
              " 'MovieReviews/17430.txt': 1.0,\n",
              " 'MovieReviews/17431.txt': 1.0,\n",
              " 'MovieReviews/17447.txt': 1.0,\n",
              " 'MovieReviews/17457.txt': 1.0,\n",
              " 'MovieReviews/17460.txt': 1.0,\n",
              " 'MovieReviews/17501.txt': 1.0,\n",
              " 'MovieReviews/17518.txt': 1.0,\n",
              " 'MovieReviews/17534.txt': 1.0,\n",
              " 'MovieReviews/17578.txt': 1.0,\n",
              " 'MovieReviews/17609.txt': 1.0,\n",
              " 'MovieReviews/17610.txt': 1.0,\n",
              " 'MovieReviews/17655.txt': 1.0,\n",
              " 'MovieReviews/17663.txt': 1.0,\n",
              " 'MovieReviews/17695.txt': 1.0,\n",
              " 'MovieReviews/17711.txt': 1.0,\n",
              " 'MovieReviews/17713.txt': 1.0,\n",
              " 'MovieReviews/17753.txt': 1.0,\n",
              " 'MovieReviews/17757.txt': 1.0,\n",
              " 'MovieReviews/17758.txt': 1.0,\n",
              " 'MovieReviews/17761.txt': 1.0,\n",
              " 'MovieReviews/17803.txt': 1.0,\n",
              " 'MovieReviews/17811.txt': 1.0,\n",
              " 'MovieReviews/17874.txt': 1.0,\n",
              " 'MovieReviews/17879.txt': 1.0,\n",
              " 'MovieReviews/17886.txt': 1.0,\n",
              " 'MovieReviews/17896.txt': 1.0,\n",
              " 'MovieReviews/17898.txt': 1.0,\n",
              " 'MovieReviews/17902.txt': 1.0,\n",
              " 'MovieReviews/17912.txt': 1.0,\n",
              " 'MovieReviews/17933.txt': 1.0,\n",
              " 'MovieReviews/17934.txt': 1.0,\n",
              " 'MovieReviews/17945.txt': 1.0,\n",
              " 'MovieReviews/17963.txt': 1.0,\n",
              " 'MovieReviews/17971.txt': 1.0,\n",
              " 'MovieReviews/17992.txt': 1.0,\n",
              " 'MovieReviews/18004.txt': 1.0,\n",
              " 'MovieReviews/18016.txt': 1.0,\n",
              " 'MovieReviews/18032.txt': 1.0,\n",
              " 'MovieReviews/18067.txt': 1.0,\n",
              " 'MovieReviews/18068.txt': 1.0,\n",
              " 'MovieReviews/18080.txt': 1.0,\n",
              " 'MovieReviews/18087.txt': 1.0,\n",
              " 'MovieReviews/18088.txt': 1.0,\n",
              " 'MovieReviews/18136.txt': 1.0,\n",
              " 'MovieReviews/18141.txt': 1.0,\n",
              " 'MovieReviews/18156.txt': 1.0,\n",
              " 'MovieReviews/18161.txt': 1.0,\n",
              " 'MovieReviews/18181.txt': 1.0,\n",
              " 'MovieReviews/18227.txt': 1.0,\n",
              " 'MovieReviews/18263.txt': 1.0,\n",
              " 'MovieReviews/18272.txt': 1.0,\n",
              " 'MovieReviews/18273.txt': 1.0,\n",
              " 'MovieReviews/18274.txt': 1.0,\n",
              " 'MovieReviews/18282.txt': 1.0,\n",
              " 'MovieReviews/18283.txt': 1.0,\n",
              " 'MovieReviews/18307.txt': 1.0,\n",
              " 'MovieReviews/18368.txt': 1.0,\n",
              " 'MovieReviews/18376.txt': 1.0,\n",
              " 'MovieReviews/18396.txt': 1.0,\n",
              " 'MovieReviews/18406.txt': 1.0,\n",
              " 'MovieReviews/18413.txt': 1.0,\n",
              " 'MovieReviews/18414.txt': 1.0,\n",
              " 'MovieReviews/18447.txt': 1.0,\n",
              " 'MovieReviews/18473.txt': 1.0,\n",
              " 'MovieReviews/18480.txt': 1.0,\n",
              " 'MovieReviews/18485.txt': 1.0,\n",
              " 'MovieReviews/18498.txt': 1.0,\n",
              " 'MovieReviews/1858.txt': 1.0,\n",
              " 'MovieReviews/1859.txt': 1.0,\n",
              " 'MovieReviews/1860.txt': 1.0,\n",
              " 'MovieReviews/1864.txt': 1.0,\n",
              " 'MovieReviews/1865.txt': 1.0,\n",
              " 'MovieReviews/1866.txt': 1.0,\n",
              " 'MovieReviews/1867.txt': 1.0,\n",
              " 'MovieReviews/1889.txt': 1.0,\n",
              " 'MovieReviews/1891.txt': 1.0,\n",
              " 'MovieReviews/1908.txt': 1.0,\n",
              " 'MovieReviews/1910.txt': 1.0,\n",
              " 'MovieReviews/1911.txt': 1.0,\n",
              " 'MovieReviews/1912.txt': 1.0,\n",
              " 'MovieReviews/1917.txt': 1.0,\n",
              " 'MovieReviews/1921.txt': 1.0,\n",
              " 'MovieReviews/1925.txt': 1.0,\n",
              " 'MovieReviews/1928.txt': 1.0,\n",
              " 'MovieReviews/1929.txt': 1.0,\n",
              " 'MovieReviews/1930.txt': 1.0,\n",
              " 'MovieReviews/1932.txt': 1.0,\n",
              " 'MovieReviews/1944.txt': 1.0,\n",
              " 'MovieReviews/1945.txt': 1.0,\n",
              " 'MovieReviews/1961.txt': 1.0,\n",
              " 'MovieReviews/1967.txt': 1.0,\n",
              " 'MovieReviews/1968.txt': 1.0,\n",
              " 'MovieReviews/1974.txt': 1.0,\n",
              " 'MovieReviews/1975.txt': 1.0,\n",
              " 'MovieReviews/1976.txt': 1.0,\n",
              " 'MovieReviews/1981.txt': 1.0,\n",
              " 'MovieReviews/1984.txt': 1.0,\n",
              " 'MovieReviews/1985.txt': 1.0,\n",
              " 'MovieReviews/1990.txt': 1.0,\n",
              " 'MovieReviews/1994.txt': 1.0,\n",
              " 'MovieReviews/2005.txt': 1.0,\n",
              " 'MovieReviews/2006.txt': 1.0,\n",
              " 'MovieReviews/2007.txt': 1.0,\n",
              " 'MovieReviews/2008.txt': 1.0,\n",
              " 'MovieReviews/2009.txt': 1.0,\n",
              " 'MovieReviews/2025.txt': 1.0,\n",
              " 'MovieReviews/2026.txt': 1.0,\n",
              " 'MovieReviews/2030.txt': 1.0,\n",
              " 'MovieReviews/2031.txt': 1.0,\n",
              " 'MovieReviews/2036.txt': 1.0,\n",
              " 'MovieReviews/2045.txt': 1.0,\n",
              " 'MovieReviews/2046.txt': 1.0,\n",
              " 'MovieReviews/2051.txt': 1.0,\n",
              " 'MovieReviews/2055.txt': 1.0,\n",
              " 'MovieReviews/2058.txt': 1.0,\n",
              " 'MovieReviews/2059.txt': 1.0,\n",
              " 'MovieReviews/2062.txt': 1.0,\n",
              " 'MovieReviews/2076.txt': 1.0,\n",
              " 'MovieReviews/2080.txt': 1.0,\n",
              " 'MovieReviews/2081.txt': 1.0,\n",
              " 'MovieReviews/2085.txt': 1.0,\n",
              " 'MovieReviews/2086.txt': 1.0,\n",
              " 'MovieReviews/2087.txt': 1.0,\n",
              " 'MovieReviews/2089.txt': 1.0,\n",
              " 'MovieReviews/2090.txt': 1.0,\n",
              " 'MovieReviews/2091.txt': 1.0,\n",
              " 'MovieReviews/2094.txt': 1.0,\n",
              " 'MovieReviews/2095.txt': 1.0,\n",
              " 'MovieReviews/2098.txt': 1.0,\n",
              " 'MovieReviews/2099.txt': 1.0,\n",
              " 'MovieReviews/2110.txt': 1.0,\n",
              " 'MovieReviews/2113.txt': 1.0,\n",
              " 'MovieReviews/2115.txt': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dtm.get_token_occurences('director'))"
      ],
      "metadata": {
        "id": "eGmKrWfMd7Cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817436f1-c0d4-4edd-b87e-ae67f86fefc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the documents that contain the word \"director\" from dictionary keys to a list\n",
        "director_docs = list(dtm.get_token_occurences('director').keys())\n",
        "director_docs"
      ],
      "metadata": {
        "id": "xiqwmeAQ1xXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5726cd1a-6161-4487-ceaf-4efc2e9a10f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MovieReviews/16748.txt',\n",
              " 'MovieReviews/17108.txt',\n",
              " 'MovieReviews/17109.txt',\n",
              " 'MovieReviews/17110.txt',\n",
              " 'MovieReviews/17111.txt',\n",
              " 'MovieReviews/17116.txt',\n",
              " 'MovieReviews/17117.txt',\n",
              " 'MovieReviews/17118.txt',\n",
              " 'MovieReviews/17119.txt',\n",
              " 'MovieReviews/17139.txt',\n",
              " 'MovieReviews/17144.txt',\n",
              " 'MovieReviews/17145.txt',\n",
              " 'MovieReviews/17146.txt',\n",
              " 'MovieReviews/17147.txt',\n",
              " 'MovieReviews/17150.txt',\n",
              " 'MovieReviews/17185.txt',\n",
              " 'MovieReviews/17192.txt',\n",
              " 'MovieReviews/17219.txt',\n",
              " 'MovieReviews/17239.txt',\n",
              " 'MovieReviews/17243.txt',\n",
              " 'MovieReviews/17254.txt',\n",
              " 'MovieReviews/17255.txt',\n",
              " 'MovieReviews/17280.txt',\n",
              " 'MovieReviews/17300.txt',\n",
              " 'MovieReviews/17303.txt',\n",
              " 'MovieReviews/17341.txt',\n",
              " 'MovieReviews/17384.txt',\n",
              " 'MovieReviews/17398.txt',\n",
              " 'MovieReviews/17399.txt',\n",
              " 'MovieReviews/17430.txt',\n",
              " 'MovieReviews/17431.txt',\n",
              " 'MovieReviews/17447.txt',\n",
              " 'MovieReviews/17457.txt',\n",
              " 'MovieReviews/17460.txt',\n",
              " 'MovieReviews/17501.txt',\n",
              " 'MovieReviews/17518.txt',\n",
              " 'MovieReviews/17534.txt',\n",
              " 'MovieReviews/17578.txt',\n",
              " 'MovieReviews/17609.txt',\n",
              " 'MovieReviews/17610.txt',\n",
              " 'MovieReviews/17655.txt',\n",
              " 'MovieReviews/17663.txt',\n",
              " 'MovieReviews/17695.txt',\n",
              " 'MovieReviews/17711.txt',\n",
              " 'MovieReviews/17713.txt',\n",
              " 'MovieReviews/17753.txt',\n",
              " 'MovieReviews/17757.txt',\n",
              " 'MovieReviews/17758.txt',\n",
              " 'MovieReviews/17761.txt',\n",
              " 'MovieReviews/17803.txt',\n",
              " 'MovieReviews/17811.txt',\n",
              " 'MovieReviews/17874.txt',\n",
              " 'MovieReviews/17879.txt',\n",
              " 'MovieReviews/17886.txt',\n",
              " 'MovieReviews/17896.txt',\n",
              " 'MovieReviews/17898.txt',\n",
              " 'MovieReviews/17902.txt',\n",
              " 'MovieReviews/17912.txt',\n",
              " 'MovieReviews/17933.txt',\n",
              " 'MovieReviews/17934.txt',\n",
              " 'MovieReviews/17945.txt',\n",
              " 'MovieReviews/17963.txt',\n",
              " 'MovieReviews/17971.txt',\n",
              " 'MovieReviews/17992.txt',\n",
              " 'MovieReviews/18004.txt',\n",
              " 'MovieReviews/18016.txt',\n",
              " 'MovieReviews/18032.txt',\n",
              " 'MovieReviews/18067.txt',\n",
              " 'MovieReviews/18068.txt',\n",
              " 'MovieReviews/18080.txt',\n",
              " 'MovieReviews/18087.txt',\n",
              " 'MovieReviews/18088.txt',\n",
              " 'MovieReviews/18136.txt',\n",
              " 'MovieReviews/18141.txt',\n",
              " 'MovieReviews/18156.txt',\n",
              " 'MovieReviews/18161.txt',\n",
              " 'MovieReviews/18181.txt',\n",
              " 'MovieReviews/18227.txt',\n",
              " 'MovieReviews/18263.txt',\n",
              " 'MovieReviews/18272.txt',\n",
              " 'MovieReviews/18273.txt',\n",
              " 'MovieReviews/18274.txt',\n",
              " 'MovieReviews/18282.txt',\n",
              " 'MovieReviews/18283.txt',\n",
              " 'MovieReviews/18307.txt',\n",
              " 'MovieReviews/18368.txt',\n",
              " 'MovieReviews/18376.txt',\n",
              " 'MovieReviews/18396.txt',\n",
              " 'MovieReviews/18406.txt',\n",
              " 'MovieReviews/18413.txt',\n",
              " 'MovieReviews/18414.txt',\n",
              " 'MovieReviews/18447.txt',\n",
              " 'MovieReviews/18473.txt',\n",
              " 'MovieReviews/18480.txt',\n",
              " 'MovieReviews/18485.txt',\n",
              " 'MovieReviews/18498.txt',\n",
              " 'MovieReviews/1858.txt',\n",
              " 'MovieReviews/1859.txt',\n",
              " 'MovieReviews/1860.txt',\n",
              " 'MovieReviews/1864.txt',\n",
              " 'MovieReviews/1865.txt',\n",
              " 'MovieReviews/1866.txt',\n",
              " 'MovieReviews/1867.txt',\n",
              " 'MovieReviews/1889.txt',\n",
              " 'MovieReviews/1891.txt',\n",
              " 'MovieReviews/1908.txt',\n",
              " 'MovieReviews/1910.txt',\n",
              " 'MovieReviews/1911.txt',\n",
              " 'MovieReviews/1912.txt',\n",
              " 'MovieReviews/1917.txt',\n",
              " 'MovieReviews/1921.txt',\n",
              " 'MovieReviews/1925.txt',\n",
              " 'MovieReviews/1928.txt',\n",
              " 'MovieReviews/1929.txt',\n",
              " 'MovieReviews/1930.txt',\n",
              " 'MovieReviews/1932.txt',\n",
              " 'MovieReviews/1944.txt',\n",
              " 'MovieReviews/1945.txt',\n",
              " 'MovieReviews/1961.txt',\n",
              " 'MovieReviews/1967.txt',\n",
              " 'MovieReviews/1968.txt',\n",
              " 'MovieReviews/1974.txt',\n",
              " 'MovieReviews/1975.txt',\n",
              " 'MovieReviews/1976.txt',\n",
              " 'MovieReviews/1981.txt',\n",
              " 'MovieReviews/1984.txt',\n",
              " 'MovieReviews/1985.txt',\n",
              " 'MovieReviews/1990.txt',\n",
              " 'MovieReviews/1994.txt',\n",
              " 'MovieReviews/2005.txt',\n",
              " 'MovieReviews/2006.txt',\n",
              " 'MovieReviews/2007.txt',\n",
              " 'MovieReviews/2008.txt',\n",
              " 'MovieReviews/2009.txt',\n",
              " 'MovieReviews/2025.txt',\n",
              " 'MovieReviews/2026.txt',\n",
              " 'MovieReviews/2030.txt',\n",
              " 'MovieReviews/2031.txt',\n",
              " 'MovieReviews/2036.txt',\n",
              " 'MovieReviews/2045.txt',\n",
              " 'MovieReviews/2046.txt',\n",
              " 'MovieReviews/2051.txt',\n",
              " 'MovieReviews/2055.txt',\n",
              " 'MovieReviews/2058.txt',\n",
              " 'MovieReviews/2059.txt',\n",
              " 'MovieReviews/2062.txt',\n",
              " 'MovieReviews/2076.txt',\n",
              " 'MovieReviews/2080.txt',\n",
              " 'MovieReviews/2081.txt',\n",
              " 'MovieReviews/2085.txt',\n",
              " 'MovieReviews/2086.txt',\n",
              " 'MovieReviews/2087.txt',\n",
              " 'MovieReviews/2089.txt',\n",
              " 'MovieReviews/2090.txt',\n",
              " 'MovieReviews/2091.txt',\n",
              " 'MovieReviews/2094.txt',\n",
              " 'MovieReviews/2095.txt',\n",
              " 'MovieReviews/2098.txt',\n",
              " 'MovieReviews/2099.txt',\n",
              " 'MovieReviews/2110.txt',\n",
              " 'MovieReviews/2113.txt',\n",
              " 'MovieReviews/2115.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "\n",
        "# Load the corpus\n",
        "corpus_root = 'MovieReviews.zip'   # make sure the folder is unzipped\n",
        "filelists = PlaintextCorpusReader(corpus_root, '.*', encoding='latin-1')\n",
        "\n",
        "# Build docs = [(author, words), ...]\n",
        "docs = []\n",
        "fileids = filelists.fileids()\n",
        "\n",
        "for i, fid in enumerate(fileids):\n",
        "    words = [w.lower() for w in filelists.words(fid)]\n",
        "    if i < 80:\n",
        "        author = \"B\"  # Berardinelli\n",
        "    else:\n",
        "        author = \"S\"  # Schwartz\n",
        "    docs.append((author, set(words)))  # use set so presence/absence is easy\n",
        "\n",
        "# --- Step 1: Create vocabulary dictionary ---\n",
        "# word -> index mapping\n",
        "vocab = {w: idx for idx, w in enumerate(set(w for _, text in docs for w in text))}\n",
        "print(\"Vocabulary size:\", len(vocab))\n"
      ],
      "metadata": {
        "id": "R4Qqi_E7B5_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e86c6e9-e0be-4d7f-a346-7b7914c4cb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 14870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy_word(word, docs):\n",
        "    n = len(docs)\n",
        "    count = sum(1 for _, text in docs if word in text)\n",
        "    p1 = count / n\n",
        "    p0 = 1 - p1\n",
        "    H = 0\n",
        "    for p in [p0, p1]:\n",
        "        if p > 0:\n",
        "            H -= p * math.log2(p)\n",
        "    return H\n",
        "\n",
        "def mutual_information_word(word, docs):\n",
        "    n = len(docs)\n",
        "    joint = defaultdict(int)\n",
        "    author_counts = Counter()\n",
        "    word_counts = Counter()\n",
        "\n",
        "    for author, text in docs:\n",
        "        x = 1 if word in text else 0\n",
        "        joint[(x, author)] += 1\n",
        "        author_counts[author] += 1\n",
        "        word_counts[x] += 1\n",
        "\n",
        "    I = 0\n",
        "    for (x, y), c in joint.items():\n",
        "        p_xy = c / n\n",
        "        p_x = word_counts[x] / n\n",
        "        p_y = author_counts[y] / n\n",
        "        I += p_xy * math.log2(p_xy / (p_x * p_y))\n",
        "    return I\n",
        "\n",
        "def top_words_mi(docs, top_n=10):\n",
        "    mi_scores = {w: mutual_information_word(w, docs) for w in vocab}\n",
        "    return sorted(mi_scores.items(), key=lambda x: -x[1])[:top_n]\n"
      ],
      "metadata": {
        "id": "o7JyDOutCCT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1\n",
        "entropy_director = entropy_word(\"director\", docs)\n",
        "print(\"Probelm 1: Entropy of 'director':\", entropy_director)\n",
        "\n",
        "# Problem 2\n",
        "mi_director = mutual_information_word(\"director\", docs)\n",
        "print(\"Problem 2: MI('director'; author):\", mi_director)\n",
        "\n",
        "# Problem 3\n",
        "top10 = top_words_mi(docs, top_n=10)\n",
        "print(\"Problem 3: Top 10 words by MI with author:\")\n",
        "for word, mi in top10:\n",
        "    print(word, mi)\n"
      ],
      "metadata": {
        "id": "KIuEn62oCHVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5bcb0f-fc59-434c-a9c5-0c6c2d0e72b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probelm 1: Entropy of 'director': 0.9956318824744184\n",
            "Problem 2: MI('director'; author): 0.27875821331328055\n",
            "Problem 3: Top 10 words by MI with author:\n",
            "schwartz 0.5636689245954639\n",
            "rights 0.5319529540927643\n",
            "dennis 0.5275548178390597\n",
            "reserved 0.5257881185821274\n",
            "reviewed 0.40770593548717765\n",
            "cast 0.40691547637735936\n",
            "Â© 0.3734286467146638\n",
            "all 0.31699472997581524\n",
            ": 0.28921242066867614\n",
            "who 0.2881056446738238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Higher MI for words to author indicates a strong presence or absence between\n",
        "# the two. Higher MI words could indicate more frequent use or a part\n",
        "# of an author's writing style. Lower MI words indicates less distinction\n",
        "# between the word and who wrote the review."
      ],
      "metadata": {
        "id": "3uIVa1M2D49K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}